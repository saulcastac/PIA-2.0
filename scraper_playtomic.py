"""
Script independiente para hacer web scraping de Playtomic
Se ejecuta peri√≥dicamente y guarda disponibilidad en archivo JSON

Uso:
    python scraper_playtomic.py [d√≠as]

Ejemplo:
    python scraper_playtomic.py      # Scrapear 3 d√≠as (hoy + 2 d√≠as m√°s) - por defecto
    python scraper_playtomic.py 3    # Scrapear 3 d√≠as (hoy + 2 d√≠as m√°s)
    
Nota: El scraper est√° limitado a m√°ximo 3 d√≠as para optimizar el rendimiento.
"""
import asyncio
import json
import sys
import os
from datetime import datetime, timedelta
from playtomic_automation import get_playtomic_instance
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)

logger = logging.getLogger(__name__)

# Configurar encoding para Windows
if hasattr(sys.stdout, 'reconfigure'):
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except:
        pass

CACHE_FILE = 'availability_cache.json'
MAX_CACHE_AGE_HOURS = 1  # Cache v√°lido por 1 hora


async def scrape_availability(days=3, club_name=None, club_url=None):
    """
    Scrapear disponibilidad de Playtomic y guardar en archivo JSON
    
    Args:
        days: N√∫mero de d√≠as a scrapear (por defecto 3)
        club_name: Nombre del club (opcional, usa config por defecto)
        club_url: URL del club (opcional, usa config por defecto)
    
    Returns:
        Diccionario con la disponibilidad por fecha
    """
    try:
        logger.info("=" * 80)
        logger.info("üöÄ INICIANDO SCRAPER DE PLAYTOMIC")
        logger.info(f"üìÖ D√≠as a scrapear: {days}")
        logger.info("=" * 80)
        
        # Obtener instancia de Playtomic
        logger.info("üîß Obteniendo instancia de Playtomic...")
        playtomic = await get_playtomic_instance()
        logger.info("‚úÖ Instancia obtenida")
        
        availability = {}
        today = datetime.now()
        
        for day_offset in range(days):
            date = today + timedelta(days=day_offset)
            date_str = date.strftime('%Y-%m-%d')
            date_formatted = date.strftime('%d/%m/%Y')
            
            logger.info("=" * 60)
            logger.info(f"üìÖ Scrapeando {date_str} ({date_formatted})...")
            logger.info("=" * 60)
            
            try:
                # Scrapear canchas disponibles para este d√≠a
                courts = await playtomic.get_available_courts(
                    date, 
                    time_slot=None,
                    club_name=club_name,
                    club_url=club_url
                )
                
                availability[date_str] = courts
                
                logger.info(f"‚úÖ {date_str}: {len(courts)} canchas encontradas")
                
                # Mostrar resumen de canchas encontradas
                if courts:
                    logger.info("üìã Canchas encontradas:")
                    for i, court in enumerate(courts[:5], 1):
                        logger.info(f"   {i}. {court.get('name', 'N/A')} - {court.get('time', 'N/A')}")
                    if len(courts) > 5:
                        logger.info(f"   ... y {len(courts) - 5} m√°s")
                
                # Pausa entre d√≠as para no sobrecargar
                if day_offset < days - 1:  # No esperar despu√©s del √∫ltimo d√≠a
                    logger.info("‚è≥ Esperando 2 segundos antes del siguiente d√≠a...")
                    await asyncio.sleep(2)
                    
            except Exception as e:
                logger.error(f"‚ùå Error scrapeando {date_str}: {e}")
                import traceback
                logger.error(traceback.format_exc())
                availability[date_str] = []
        
        # Guardar en archivo JSON
        cache_data = {
            'timestamp': datetime.now().isoformat(),
            'scraped_days': days,
            'availability': availability
        }
        
        logger.info("=" * 60)
        logger.info(f"üíæ Guardando disponibilidad en {CACHE_FILE}...")
        
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, indent=2, ensure_ascii=False)
        
        # Calcular estad√≠sticas
        total_courts = sum(len(courts) for courts in availability.values())
        days_with_courts = sum(1 for courts in availability.values() if len(courts) > 0)
        
        logger.info("=" * 80)
        logger.info("‚úÖ SCRAPING COMPLETADO")
        logger.info(f"üìä Total de canchas encontradas: {total_courts}")
        logger.info(f"üìÖ D√≠as con disponibilidad: {days_with_courts}/{days}")
        logger.info(f"üíæ Cache guardado en: {CACHE_FILE}")
        logger.info("=" * 80)
        
        return availability
        
    except Exception as e:
        logger.error(f"‚ùå Error en scraping: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {}


def load_availability_cache():
    """
    Cargar disponibilidad desde cache JSON
    
    Returns:
        Diccionario con disponibilidad si el cache es v√°lido, None si no
    """
    try:
        if not os.path.exists(CACHE_FILE):
            logger.debug(f"Cache file {CACHE_FILE} no existe")
            return None
        
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Verificar que el cache no sea muy viejo
        cache_time = datetime.fromisoformat(data['timestamp'])
        age_hours = (datetime.now() - cache_time).total_seconds() / 3600
        
        if age_hours > MAX_CACHE_AGE_HOURS:
            logger.info(f"‚ö†Ô∏è  Cache expirado (edad: {age_hours:.1f} horas)")
            return None
        
        logger.info(f"‚úÖ Cache v√°lido (edad: {age_hours:.1f} horas)")
        return data.get('availability', {})
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Error cargando cache: {e}")
        return None


async def main():
    """Funci√≥n principal"""
    # Obtener n√∫mero de d√≠as desde argumentos
    # Por defecto: 3 d√≠as (hoy + 2 d√≠as m√°s)
    days = 3
    if len(sys.argv) > 1:
        try:
            days = int(sys.argv[1])
            if days < 1 or days > 30:
                logger.warning(f"‚ö†Ô∏è  N√∫mero de d√≠as inv√°lido ({days}), usando 3 por defecto")
                days = 3
        except ValueError:
            logger.warning(f"‚ö†Ô∏è  Argumento inv√°lido, usando 3 d√≠as por defecto")
    
    # Limitar a m√°ximo 3 d√≠as (hoy + 2 d√≠as m√°s)
    if days > 3:
        logger.info(f"‚ö†Ô∏è  Limitando a 3 d√≠as (hoy + 2 d√≠as m√°s). Solicitado: {days}")
        days = 3
    
    logger.info(f"üìÖ Scrapeando {days} d√≠as: hoy + {days-1} d√≠as m√°s")
    
    # Ejecutar scraping
    await scrape_availability(days=days)
    
    # Cerrar instancia de Playtomic
    try:
        playtomic = await get_playtomic_instance()
        await playtomic.close()
    except:
        pass


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è  Scraping interrumpido por el usuario")
    except Exception as e:
        logger.error(f"‚ùå Error fatal: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)

